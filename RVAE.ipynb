{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RVAE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h0f6fQvhr3j"
      },
      "source": [
        "\"\"\"all necessary imports\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import Tensor\n",
        "import cv2\n",
        "import glob\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ647NNuhulJ"
      },
      "source": [
        "\"\"\"selects 1000 images randomly\"\"\"\n",
        "\"\"\"set the path to where the training set is saved on your system\"\"\"\n",
        "import os\n",
        "filenames = [img for img in glob.glob(\"path/to/images/*.jpg\")]\n",
        "np.random.shuffle(filenames)\n",
        "filenames = filenames[:1000]\n",
        "images = [cv2.imread(img) for img in filenames]\n",
        "for i in range(0,len(images)):\n",
        "    images[i] = cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB)\n",
        "    images[i] = cv2.resize(images[i], (400,400))\n",
        "images = np.array(images)\n",
        "images = images.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsj0Ud4Khx7Q"
      },
      "source": [
        "\"\"\"custom layer which produces the distribution which is sampled in the VAE\"\"\"\n",
        "\n",
        "class Latent_features(tf.keras.layers.Layer):\n",
        "    def call(self, inputs) -> Tensor:\n",
        "        dist_mean, dist_log_var = inputs\n",
        "        batch = tf.shape(dist_mean)[0]\n",
        "        dim = tf.shape(dist_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return dist_mean + tf.exp(0.5 * dist_log_var) * epsilon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0aLpWKHh20i"
      },
      "source": [
        "class RVAE(tf.keras.Model):\n",
        "    \n",
        "    \"\"\"builds encoder and decoder sub-networks\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(RVAE, self).__init__()\n",
        "        self.encoder = self.build_encoder()\n",
        "        self.decoder = self.build_decoder()\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "        \n",
        "        autoencoder_input = keras.Input(shape=(400,400,3))\n",
        "        encoded_img = self.encoder(autoencoder_input)[2]\n",
        "        decoded_img = self.decoder(encoded_img)\n",
        "        self.autoencoder = keras.Model(autoencoder_input, decoded_img)\n",
        "    \n",
        "    \"\"\"custom call function necessary for custom keras model\"\"\"\n",
        "    def call(self, image):\n",
        "        encoded = self.encoder(image)[2]\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "    \n",
        "    \"\"\"utility function for batch norm and leakyrelu\"\"\"\n",
        "    def activation_block(self, inputs) -> Tensor:\n",
        "        BN = tf.keras.layers.BatchNormalization(momentum=0.99) (inputs)\n",
        "        activated = tf.keras.layers.LeakyReLU()(BN)\n",
        "        return activated\n",
        "    \n",
        "    \"\"\"implements skip connection for the resnet component of the architecture\"\"\"\n",
        "    def residual_block(self, inputs: Tensor, scale_change: bool, polarity, kernel_size = 2, filters = 64, stride_size = 2) -> Tensor:\n",
        "        #POLARITY IS 0 IF DOWNSCALING (ENCODER) 1 IF UPSCALING (DECODER)\n",
        "        if polarity == 0:\n",
        "            output_1 = tf.keras.layers.Conv2D(filters, (kernel_size, kernel_size), strides = (1 if not scale_change else stride_size), padding = 'same') (inputs)\n",
        "            output_1 = self.activation_block(output_1)\n",
        "            output_1 = tf.keras.layers.Conv2D(filters, (kernel_size, kernel_size), strides = (1), padding = 'same') (output_1)\n",
        "            if scale_change == True:\n",
        "                inputs = tf.keras.layers.Conv2D(filters, (kernel_size, kernel_size), strides = (stride_size), padding = 'same') (inputs)\n",
        "        \n",
        "        else:\n",
        "            output_1 = tf.keras.layers.Conv2DTranspose(filters, (kernel_size, kernel_size), strides = (1 if not scale_change else stride_size), padding = 'same') (inputs)\n",
        "            output_1 = self.activation_block(output_1)\n",
        "            output_1 = tf.keras.layers.Conv2DTranspose(filters, (kernel_size, kernel_size), strides = (1), padding = 'same') (output_1)\n",
        "            if scale_change == True:\n",
        "                inputs = tf.keras.layers.Conv2DTranspose(filters, (kernel_size, kernel_size), strides = (stride_size), padding = 'same') (inputs)\n",
        "        \n",
        "        output_2 = tf.keras.layers.Add()([inputs, output_1])\n",
        "        output_2 = self.activation_block(output_2)\n",
        "        \n",
        "        return(output_2)\n",
        "        \n",
        "    \"\"\"returns the encoder model, a sub-architecture of the autoencoder\"\"\"\n",
        "    def build_encoder(self):\n",
        "        E_input = tf.keras.layers.Input(shape = (400,400,3), name = 'original_image')\n",
        "        E = tf.keras.layers.Conv2D(32, (1,1), strides=(1), padding = 'same') (E_input)\n",
        "        E = self.activation_block(E)\n",
        "        \n",
        "        block_depths = [2,5,5,2]\n",
        "        filters = [32,64,64,128]\n",
        "        \n",
        "        for i in range(0,len(block_depths)):\n",
        "            for j in range(0,block_depths[i]):\n",
        "                E = self.residual_block(E, (j==0 and i!=0), 0, 2, filters[i], 2)\n",
        "\n",
        "        \n",
        "            \n",
        "        self.reshape_dims = E.shape\n",
        "            \n",
        "        E = tf.keras.layers.Flatten() (E)\n",
        "        \n",
        "        self.flatten_dims = E.shape\n",
        "        \n",
        "        E = (tf.keras.layers.LeakyReLU()) (E)\n",
        "        \n",
        "        distribution_mean = tf.keras.layers.Dense(16, name='mean')(E)\n",
        "        distribution_variance = tf.keras.layers.Dense(16, name='log_variance')(E)\n",
        "        latent_encoding = Latent_features()([distribution_mean, distribution_variance])\n",
        "        \n",
        "        \n",
        "        encoder = keras.Model(E_input, [distribution_mean, distribution_variance, latent_encoding], name=\"encoder\")\n",
        "        \n",
        "                \n",
        "        return encoder\n",
        "    \n",
        "    \"\"\"returns the decoder model, a sub-network for autoencoder architecture\"\"\"\n",
        "    def build_decoder(self):\n",
        "        decoder_input = keras.Input(shape=(16,))\n",
        "        D = tf.keras.layers.LeakyReLU() (decoder_input)\n",
        "        D = (tf.keras.layers.Dense(self.flatten_dims[1])) (D)\n",
        "        D = (tf.keras.layers.LeakyReLU()) (D)\n",
        "        D = (tf.keras.layers.Reshape((self.reshape_dims[1], self.reshape_dims[2], self.reshape_dims[3]))) (D)\n",
        "        \n",
        "        block_depths = [2,5,5,2]\n",
        "        filters = [128,64,64,32]\n",
        "        \n",
        "        for i in range(0,len(block_depths)):\n",
        "            for j in range(0,block_depths[i]):\n",
        "                D = self.residual_block(D, (j==0 and i!=0), 1, 2, filters[i], 2)\n",
        "            \n",
        "        D = tf.keras.layers.Conv2DTranspose(3, (1,1), strides = (1), padding = 'same') (D)\n",
        "        D = self.activation_block(D)\n",
        "        \n",
        "        \n",
        "        decoded = (tf.keras.layers.Activation('sigmoid')) (D)\n",
        "        \n",
        "        decoder = tf.keras.Model(inputs = decoder_input, outputs = decoded)\n",
        "        \n",
        "        return decoder\n",
        "\n",
        "    \n",
        "    \"\"\"necessary for loss trackers used for custom loss function\"\"\"\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            mean, log_var, latent = self.encoder(data)\n",
        "            reconstruction = self.decoder(latent)\n",
        "            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n",
        "            kl_loss = -0.5 * (1 + log_var - tf.square(mean) - tf.exp(log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bETJDQU3h48l"
      },
      "source": [
        "\"\"\"compiling the RVAE with RMSprop\"\"\"\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate = 0.0001)\n",
        "rvae = RVAE()\n",
        "\n",
        "\n",
        "rvae.compile(optimizer=opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_NuDAmrh7IE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}